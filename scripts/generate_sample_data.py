"""
MVPìš© ì¸í”Œë£¨ì–¸ì„œ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (í™•ì¥íŒ)
====================================================

ë‘ ê°€ì§€ í˜•íƒœì˜ ë°ì´í„° ìƒì„±:
1. influencers_raw.json: í¬ë¡¤ëŸ¬ì—ì„œ ìˆ˜ì§‘í•œ í˜•íƒœ (ë¶„ë¥˜/ë¶„ì„ ì—†ìŒ)
2. influencers_data.json: Processorì—ì„œ ì²˜ë¦¬ëœ í˜•íƒœ (ë¶„ë¥˜/ë¶„ì„ ì™„ë£Œ)

Instagram Graph API ìŠ¤í‚¤ë§ˆì— ë§ëŠ” 150ëª…ì˜ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
- Expert (í—¤ì–´ ì „ë¬¸ê°€): 70ëª… (ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€, ì„±ë³„ ì „ë¬¸ì„±)
- Trendsetter (íŒ¨ì…˜/ë¼ì´í”„ìŠ¤íƒ€ì¼): 80ëª… (ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€, ìŠ¤íƒ€ì¼)

FIS ì ìˆ˜ ë¶„í¬:
- ì‹ ë¢° ê°€ëŠ¥ (80-98): ì•½ 60%
- ì£¼ì˜ í•„ìš” (60-79): ì•½ 25%
- ìœ„í—˜ (40-59): ì•½ 15%

ê° ì¸í”Œë£¨ì–¸ì„œë‹¹ ìµœëŒ€ 10ê°œì˜ ë¦´ìŠ¤(VIDEO) ê²Œì‹œë¬¼ í¬í•¨
"""

import json
import random
from datetime import datetime, timedelta
from pathlib import Path


# ============================================================
# ë°ì´í„° ìƒì„±ìš© ìƒìˆ˜
# ============================================================

# Expertìš© ë°ì´í„° (120ëª… - ë‹¤ì–‘í•œ ì „ë¬¸ ë¶„ì•¼)
# ë™ì  ìƒì„±ì„ ìœ„í•œ ë² ì´ìŠ¤ ì´ë¦„ë“¤
EXPERT_USERNAME_BASES = [
    # ì—¬ì„± íƒ€ê²Ÿ ì „ë¬¸ê°€ (ì—¼ìƒ‰/íŒ) - 40ëª…
    "hair_master", "salon_beauty", "color_specialist", "perm_artist",
    "cheongdam_hair", "gangnam_stylist", "hair_clinic", "beauty_director",
    "styling_pro", "color_queen", "hair_doctor", "salon_style",
    "premium_hair", "hair_healing", "style_creator", "hair_lab",
    "beauty_hair", "salon_director", "hair_specialist", "color_master",
    "perm_pro", "hair_artist", "beauty_expert", "salon_master",
    "hair_designer", "color_artist", "perm_specialist", "hair_studio",
    "beauty_lab", "salon_expert", "hair_pro", "style_expert",
    "hair_queen", "color_pro", "perm_master", "beauty_studio",
    "salon_pro", "hair_center", "style_master", "beauty_center",
    # ë‚¨ì„± íƒ€ê²Ÿ ì „ë¬¸ê°€ - 25ëª…
    "mens_hair", "barber_master", "mens_cut", "gentleman_salon",
    "barber_shop", "mens_style", "male_hair", "barber_artist",
    "mens_grooming", "gentleman_barber", "mens_salon", "barber_pro",
    "male_grooming", "mens_designer", "barber_studio", "gentleman_style",
    "mens_expert", "barber_lab", "male_stylist", "mens_clinic",
    "barber_center", "gentleman_cut", "mens_master", "barber_expert",
    "male_barber",
    # ì¤‘ë…„/ì‹œë‹ˆì–´ ì „ë¬¸ê°€ - 20ëª…
    "mature_hair", "senior_beauty", "ageless_salon", "midlife_hair",
    "silver_hair", "classic_beauty", "elegant_hair", "timeless_style",
    "graceful_hair", "premium_age", "mature_style", "senior_salon",
    "ageless_beauty", "midlife_style", "silver_salon", "classic_hair",
    "elegant_beauty", "timeless_hair", "graceful_salon", "premium_mature",
    # ë‘í”¼/íƒˆëª¨ ì „ë¬¸ê°€ - 20ëª…
    "scalp_healing", "hair_loss", "trichology", "scalp_doctor",
    "hair_regrowth", "alopecia_care", "healthy_scalp", "hair_restoration",
    "scalp_care", "hair_health", "scalp_clinic", "hair_therapy",
    "scalp_expert", "hair_recovery", "scalp_pro", "hair_solution",
    "scalp_master", "hair_renewal", "scalp_lab", "hair_revive",
    # ì›¨ë”©/íŠ¹ìˆ˜ í—¤ì–´ - 15ëª…
    "wedding_hair", "bridal_beauty", "special_occasion", "event_stylist",
    "celebrity_hair", "photoshoot_hair", "wedding_style", "bridal_salon",
    "occasion_hair", "event_hair", "celeb_stylist", "studio_hair",
    "wedding_pro", "bridal_expert", "special_hair",
]

def generate_expert_usernames(count: int) -> list:
    """Expert ìœ ì €ë„¤ì„ ë™ì  ìƒì„±"""
    usernames = []
    suffixes = ["_kim", "_lee", "_park", "_cho", "_jung", "_oh", "_han", "_yoon",
                "_seoul", "_korea", "_pro", "_lab", "_studio", "_center", "_k", "_j", "_m", "_y"]
    for i, base in enumerate(EXPERT_USERNAME_BASES):
        if len(usernames) >= count:
            break
        suffix = suffixes[i % len(suffixes)]
        usernames.append(f"{base}{suffix}")
    # ë¶€ì¡±í•˜ë©´ ë²ˆí˜¸ ë¶™ì—¬ì„œ ì¶”ê°€
    while len(usernames) < count:
        idx = len(usernames)
        base = EXPERT_USERNAME_BASES[idx % len(EXPERT_USERNAME_BASES)]
        usernames.append(f"{base}_{idx}")
    return usernames[:count]

EXPERT_USERNAMES = generate_expert_usernames(120)

# ì „ë¬¸ê°€ ë°”ì´ì˜¤ - íƒ€ê²Ÿ ì—°ë ¹ëŒ€/ì„±ë³„ë³„ ë¶„ë¥˜
EXPERT_BIOS_FEMALE_YOUNG = [  # 20ëŒ€ ì—¬ì„± íƒ€ê²Ÿ
    "ì²­ë‹´ë™ í—¤ì–´ì‚´ë¡± ì›ì¥ | 15ë…„ì°¨ ë¯¸ìš©ì‚¬ | ì—¼ìƒ‰ & íŒ ì „ë¬¸ | ì˜ˆì•½ë¬¸ì˜ DM",
    "ê°•ë‚¨ í”„ë¦¬ë¯¸ì—„ í—¤ì–´ìˆ | ì»¬ëŸ¬ë¦¬ìŠ¤íŠ¸ | ì†ìƒëª¨ ë³µêµ¬ ì „ë¬¸ | ì¹´ì¹´ì˜¤í†¡ ì˜ˆì•½",
    "í™ëŒ€ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸ | 10ë…„ ê²½ë ¥ | íŠ¸ë Œë””í•œ ì—¼ìƒ‰ | ì˜ˆì•½ ë§í¬ â¬‡ï¸",
    "ì••êµ¬ì • ì‚´ë¡± ë””ë ‰í„° | íŒ ì „ë¬¸ê°€ | ìì—°ìŠ¤ëŸ¬ìš´ ì›¨ì´ë¸Œ | DM ì˜ˆì•½",
    "ì‹ ì‚¬ë™ í—¤ì–´ì‚´ë¡± | 12ë…„ì°¨ ë””ìì´ë„ˆ | ë³¼ë¥¨íŒ ì „ë¬¸ | ì˜ˆì•½ë¬¸ì˜ ì¹´í†¡",
    "ì²­ë‹´ ì»¬ëŸ¬ ì „ë¬¸ìˆ | í•˜ì´í†¤ ì—¼ìƒ‰ | ë¸”ë¦¬ì¹˜ ì „ë¬¸ | ì˜ˆì•½ DM",
    "ì„œì´ˆ í”„ë¦¬ë¯¸ì—„ì‚´ë¡± | í—¤ì–´í´ë¦¬ë‹‰ | ì†ìƒëª¨ íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ | DM ìƒë‹´",
    "ë§ˆí¬ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸ | ì—¼ìƒ‰ ì „ë¬¸ | ì• ì‰¬ê³„ì—´ ì»¬ëŸ¬ | ì˜ˆì•½ë¬¸ì˜",
    "ìš©ì‚° í—¤ì–´ì•„í‹°ìŠ¤íŠ¸ | Cì»¬íŒ ì „ë¬¸ | ìì—°ìŠ¤ëŸ¬ìš´ ë³¼ë¥¨ | DM ì˜ˆì•½",
    "ì„±ìˆ˜ íŠ¸ë Œë””ì‚´ë¡± | MZ ê°ì„± | ë ˆì´ì–´ë“œì»· ì „ë¬¸ | DM ì˜ˆì•½",
]

EXPERT_BIOS_FEMALE_MATURE = [  # 30~40ëŒ€ ì—¬ì„± íƒ€ê²Ÿ
    "ê°•ë‚¨ í”„ë¦¬ë¯¸ì—„ì‚´ë¡± | 30ëŒ€ ì—¬ì„± ì „ë¬¸ | ìì—°ìŠ¤ëŸ¬ìš´ ë³¼ë¥¨íŒ | ì˜ˆì•½ DM",
    "ëª©ë™ ì‚´ë¡±ì›ì¥ | 20ë…„ ê²½ë ¥ | ì¤‘ë…„ í—¤ì–´ ì „ë¬¸ | ìƒë‹´ì˜ˆì•½ DM",
    "ë¶„ë‹¹ í”„ë¦¬ë¯¸ì—„í—¤ì–´ | 15ë…„ì°¨ ì›ì¥ | VIP ê³ ê° ì „ë‹´ | ì˜ˆì•½ DM",
    "íŒêµ í—¤ì–´ì‚´ë¡± | 40ëŒ€ ì—¬ì„± ë§ì¶¤ | ì»¤ë²„ ê·¸ë ˆì´ ì „ë¬¸ | ì¹´ì¹´ì˜¤ ì˜ˆì•½",
    "ì¼ì‚° ë·°í‹°ì‚´ë¡± | 30~40ëŒ€ ì „ë¬¸ | ìš°ì•„í•œ ìŠ¤íƒ€ì¼ë§ | DM ìƒë‹´",
    "ìš©ì¸ í”„ë¦¬ë¯¸ì—„í—¤ì–´ | ì¤‘ë…„ ì—¬ì„± í—¤ì–´ | ë³¼ë¥¨ & ìœ¤ê¸° | ì˜ˆì•½ë¬¸ì˜",
    "ìˆ˜ì› ì‚´ë¡±ë””ë ‰í„° | 18ë…„ ê²½ë ¥ | ì„¸ë ¨ëœ ì¤‘ë…„ ìŠ¤íƒ€ì¼ | ì¹´í†¡ ì˜ˆì•½",
    "ì†¡íŒŒ í—¤ì–´í´ë¦¬ë‹‰ | 30ëŒ€ ì§ì¥ì¸ ì „ë¬¸ | ê´€ë¦¬ ì‰¬ìš´ ìŠ¤íƒ€ì¼ | DM",
    "ì„œì´ˆ ë·°í‹°ìŠ¤íŠœë””ì˜¤ | 40ëŒ€ ë§ì¶¤ ì»¬ëŸ¬ | ìƒˆì¹˜ ì¼€ì–´ | ì˜ˆì•½ DM",
    "ê°•ë™ í”„ë¦¬ë¯¸ì—„ì‚´ë¡± | ì¤‘ë…„ ë³¼ë¥¨íŒ | ìì—°ìŠ¤ëŸ¬ìš´ ì»¬ | ìƒë‹´ì˜ˆì•½",
]

EXPERT_BIOS_MALE = [  # ë‚¨ì„± íƒ€ê²Ÿ
    "ê°•ë‚¨ì—­ í—¤ì–´ìŠ¤íŠœë””ì˜¤ | 8ë…„ì°¨ ë¯¸ìš©ì‚¬ | ë‚¨ì„± ì»¤íŠ¸ ì „ë¬¸ | ì˜ˆì•½ë¬¸ì˜",
    "í™ëŒ€ ë°”ë²„ìƒµ | ë‚¨ì„± ì „ë¬¸ | íˆ¬ë¸”ëŸ­ & í˜ì´ë“œ | DM ì˜ˆì•½",
    "ì²­ë‹´ ë§¨ì¦ˆí—¤ì–´ | ë‚¨ì„± ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸ | ë¹„ì¦ˆë‹ˆìŠ¤ë£© ì „ë¬¸ | ì¹´ì¹´ì˜¤í†¡",
    "ê°•ë‚¨ ë°”ë²„ë§ˆìŠ¤í„° | 10ë…„ì°¨ | ë‚¨ì„± ê·¸ë£¨ë° ì „ë¬¸ | ì˜ˆì•½ DM",
    "ì„œì´ˆ ë§¨ì¦ˆì‚´ë¡± | ë‚¨ì„± íŒ ì „ë¬¸ê°€ | ë³¼ë¥¨ & ë‹¤ìš´íŒ | ìƒë‹´ë¬¸ì˜",
    "ì—­ì‚¼ ë°”ë²„ìƒµ | ë‚¨ì„± ë‘í”¼ì¼€ì–´ | íƒˆëª¨ ì˜ˆë°© ì „ë¬¸ | DM ì˜ˆì•½",
    "ì‚¼ì„± ë§¨ì¦ˆìŠ¤íŠœë””ì˜¤ | ì§ì¥ì¸ ë‚¨ì„± ì „ë¬¸ | ê¹”ë”í•œ ìŠ¤íƒ€ì¼ | ì˜ˆì•½",
    "ì ì‹¤ ë‚¨ì„±í—¤ì–´ | 20ëŒ€ ë‚¨ì„± ì „ë¬¸ | íŠ¸ë Œë””í•œ ì»¤íŠ¸ | ì¹´í†¡ ì˜ˆì•½",
    "ì†¡íŒŒ ë°”ë²„í´ëŸ½ | ë‚¨ì„± ê·¸ë£¨ë° | ë©´ë„ & í—¤ì–´ | DM ìƒë‹´",
    "ê°•ì„œ ë§¨ì¦ˆí—¤ì–´ë© | 30ëŒ€ ë‚¨ì„± ë§ì¶¤ | ë³¼ë¥¨ê° ìˆëŠ” ìŠ¤íƒ€ì¼ | ì˜ˆì•½",
]

EXPERT_BIOS_SCALP = [  # ë‘í”¼/íƒˆëª¨ ì „ë¬¸
    "ì„±ìˆ˜ë™ í—¤ì–´ë© | ë‘í”¼ì¼€ì–´ ì „ë¬¸ | íƒˆëª¨ ì˜ˆë°© í´ë¦¬ë‹‰ | ìƒë‹´ë¬¸ì˜ DM",
    "ì†¡íŒŒ í—¤ì–´ì‚´ë¡± | ë‘í”¼ê´€ë¦¬ | íƒˆëª¨ì¼€ì–´ ì „ë¬¸ | ì¹´ì¹´ì˜¤ ì˜ˆì•½",
    "ê°•ë‚¨ ë‘í”¼í´ë¦¬ë‹‰ | íƒˆëª¨ ì „ë¬¸ | ëª¨ë°œ ì´ì‹ ìƒë‹´ | ì˜ˆì•½ DM",
    "ì„œì´ˆ íŠ¸ë¦¬ì½œë¡œì§€ | ë‘í”¼ ì§„ë‹¨ ì „ë¬¸ | ë§ì¶¤ ì¼€ì–´ | ìƒë‹´ë¬¸ì˜",
    "ë¶„ë‹¹ í—¤ì–´í´ë¦¬ë‹‰ | íƒˆëª¨ ì˜ˆë°© | ë‘í”¼ ìŠ¤ì¼€ì¼ë§ | DM ì˜ˆì•½",
    "ì¼ì‚° ë‘í”¼ì„¼í„° | ì—¬ì„± íƒˆëª¨ ì „ë¬¸ | ë³¼ë¥¨ ì¼€ì–´ | ì¹´ì¹´ì˜¤ ìƒë‹´",
    "ìˆ˜ì› ëª¨ë°œí´ë¦¬ë‹‰ | ë‚¨ì„± íƒˆëª¨ | Mì ì¼€ì–´ ì „ë¬¸ | ì˜ˆì•½ë¬¸ì˜",
    "ìš©ì¸ ë‘í”¼íë§ | ì§€ì„± ë‘í”¼ ì „ë¬¸ | ë¹„ë“¬ ì¼€ì–´ | DM ìƒë‹´",
]

EXPERT_BIOS_WEDDING = [  # ì›¨ë”©/íŠ¹ìˆ˜ í—¤ì–´
    "ì ì‹¤ í—¤ì–´ë””ìì´ë„ˆ | ì›¨ë”©í—¤ì–´ ì „ë¬¸ | ì—…ìŠ¤íƒ€ì¼ | ì˜ˆì•½ ì¹´ì¹´ì˜¤í†¡",
    "ì²­ë‹´ ë¸Œë¼ì´ëœ | ì›¨ë”© ì „ë¬¸ | ì‹ ë¶€ í—¤ì–´ë©”ì´í¬ì—… | ìƒë‹´ DM",
    "ê°•ë‚¨ ì›¨ë”©ìŠ¤íŠœë””ì˜¤ | íŠ¹ë³„í•œ ë‚  ì „ë¬¸ | ì´ë²¤íŠ¸ í—¤ì–´ | ì˜ˆì•½ë¬¸ì˜",
    "ì••êµ¬ì • ë¸Œë¼ì´ëœí—¤ì–´ | ì›¨ë”©ì´¬ì˜ ì „ë¬¸ | ì—…ìŠ¤íƒ€ì¼ | ì¹´ì¹´ì˜¤í†¡",
    "ì„œì´ˆ íŒŒí‹°í—¤ì–´ | í–‰ì‚¬ í—¤ì–´ ì „ë¬¸ | ì—°ì˜ˆì¸ ìŠ¤íƒ€ì¼ | DM ì˜ˆì•½",
    "ëª©ë™ ì›¨ë”©ì‚´ë¡± | ê²°í˜¼ì‹ í—¤ì–´ | í•˜ê° ìŠ¤íƒ€ì¼ë§ | ìƒë‹´ë¬¸ì˜",
]

# ê¸°ë³¸ ë°”ì´ì˜¤ (í˜¼í•©)
EXPERT_BIOS = (EXPERT_BIOS_FEMALE_YOUNG + EXPERT_BIOS_FEMALE_MATURE +
              EXPERT_BIOS_MALE + EXPERT_BIOS_SCALP + EXPERT_BIOS_WEDDING)

EXPERT_CAPTIONS = [
    "ì˜¤ëŠ˜ì˜ ì‹œìˆ  - ì›œí†¤ ê³ ê°ë‹˜ê»˜ ì–´ìš¸ë¦¬ëŠ” ê°€ì„ ì—¼ìƒ‰ ë ˆì‹œí”¼ ê³µê°œ! #ì—¼ìƒ‰ì•½ #í—¤ì–´ì»¬ëŸ¬ #ë¯¸ìš©ì‚¬ì¼ìƒ",
    "Cì»¬ íŒ ì‹œìˆ  ê³¼ì • í’€ì˜ìƒ! ìì—°ìŠ¤ëŸ¬ìš´ ë³¼ë¥¨ê° ì‚´ë¦¬ëŠ” ë¹„ë²• #íŒ #ì‹œìˆ ì˜ìƒ #ì‚´ë¡±",
    "ì†ìƒëª¨ ì¼€ì–´ ì „í›„ ë¹„êµ! í´ë¦¬ë‹‰ íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ íš¨ê³¼ #í—¤ì–´í´ë¦¬ë‹‰ #ì†ìƒëª¨ì¼€ì–´",
    "ì• ì‰¬ë¸Œë¼ìš´ ì—¼ìƒ‰ ì‹œìˆ  ğŸ¨ ì¿¨í†¤ ê³ ê°ë‹˜ ë§ì¶¤ ì»¬ëŸ¬ #ì• ì‰¬ë¸Œë¼ìš´ #ì—¼ìƒ‰ì „ë¬¸",
    "ë³¼ë¥¨íŒ ì‹œìˆ  ì™„ë£Œ! ë¿Œë¦¬ë³¼ë¥¨ ì‚´ë¦¬ëŠ” í…Œí¬ë‹‰ ê³µê°œ #ë³¼ë¥¨íŒ #íŒì „ë¬¸",
    "ë¸”ë¦¬ì¹˜ ì—†ì´ í•˜ì´í†¤ ì—¼ìƒ‰í•˜ê¸° ğŸ’« ì†ìƒ ìµœì†Œí™” ë¹„ë²• #í•˜ì´í†¤ì—¼ìƒ‰ #ì»¬ëŸ¬ë¦¬ìŠ¤íŠ¸",
    "ë ˆì´ì–´ë“œì»· ì‹œìˆ  ì˜ìƒ âœ‚ï¸ ì–¼êµ´í˜•ì— ë§ëŠ” ì»¤íŠ¸ë¼ì¸ #ë ˆì´ì–´ë“œì»· #ì»¤íŠ¸ì „ë¬¸",
    "ë‘í”¼ ìŠ¤ì¼€ì¼ë§ ì „í›„ ë¹„êµ! ê±´ê°•í•œ ë‘í”¼ ë§Œë“¤ê¸° #ë‘í”¼ì¼€ì–´ #íƒˆëª¨ì˜ˆë°©",
    "ì›¨ë”©í—¤ì–´ ì—…ìŠ¤íƒ€ì¼ ì‹œìˆ  ğŸ‘° ì‹ ë¶€ë‹˜ í—¤ì–´ ì™„ì„± #ì›¨ë”©í—¤ì–´ #ì—…ìŠ¤íƒ€ì¼",
    "ë‚¨ì„± íˆ¬ë¸”ëŸ­ ì»¤íŠ¸ ì‹œìˆ  ğŸ’‡â€â™‚ï¸ ê¹”ë”í•œ ë¼ì¸ ì •ë¦¬ #ë‚¨ì„±ì»¤íŠ¸ #íˆ¬ë¸”ëŸ­",
    "ì—¼ìƒ‰ì•½ ì¡°ìƒ‰ ê³¼ì • ê³µê°œ! ë§ì¶¤ ì»¬ëŸ¬ ë§Œë“¤ê¸° #ì¡°ìƒ‰ #ì»¬ëŸ¬ë ˆì‹œí”¼",
    "íˆí”¼íŒ ì‹œìˆ  ì™„ë£Œ ğŸŒŠ ìì—°ìŠ¤ëŸ¬ìš´ ì›¨ì´ë¸Œ ì—°ì¶œ #íˆí”¼íŒ #ì›¨ì´ë¸ŒíŒ",
    "íƒˆìƒ‰ í›„ í†¤ë‹¤ìš´ ì—¼ìƒ‰ ì‹œìˆ  ğŸ¨ ì†ìƒ ì¼€ì–´ í¬í•¨ #í†¤ë‹¤ìš´ #ì—¼ìƒ‰ì‹œìˆ ",
    "ìˆ±ì¹˜ê¸° ì—†ì´ ë³¼ë¥¨ê° ì‚´ë¦¬ëŠ” ì»¤íŠ¸ í…Œí¬ë‹‰ âœ‚ï¸ #ë³¼ë¥¨ì»¤íŠ¸ #ì‹œìˆ ì˜ìƒ",
    "í´ë¦¬ë‹‰ íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ ì‹œìˆ  ê³¼ì • ğŸ’†â€â™€ï¸ ì†ìƒëª¨ ì§‘ì¤‘ ì¼€ì–´ #í—¤ì–´í´ë¦¬ë‹‰ #íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸",
]

# Trendsetterìš© ë°ì´í„° (180ëª… - ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€, ìŠ¤íƒ€ì¼)
TRENDSETTER_USERNAME_BASES = [
    # 20ëŒ€ ì—¬ì„± (MZì„¸ëŒ€) - 70ëª…
    "haru_style", "minjung_daily", "yuna_ootd", "seo_fashion", "jin_lookbook",
    "hyun_daily", "sua_style", "minji_look", "yeonhee_ootd", "jiwon_fashion",
    "hana_daily", "sooyeon_style", "eunji_look", "dahyun_ootd", "chaeyoung_life",
    "nayeon_style", "jihyo_daily", "momo_look", "sana_ootd", "tzuyu_fashion",
    "rose_style", "jennie_daily", "lisa_look", "jisoo_ootd", "irene_fashion",
    "seulgi_style", "wendy_daily", "joy_look", "yeri_ootd", "winter_fashion",
    "karina_style", "giselle_daily", "ningning_look", "yujin_ive", "wonyoung_ootd",
    "leeseo_style", "gaeul_daily", "rei_look", "liz_ootd", "kazuha_fashion",
    "sakura_style", "chaewon_daily", "yunjin_look", "eunchae_ootd", "sullyoon_fashion",
    "haewon_style", "bae_daily", "jiwoo_look", "lily_ootd", "kyujin_fashion",
    "yeji_style", "lia_daily", "ryujin_look", "chaeryeong_ootd", "yuna_fashion",
    "minju_style", "yujin_daily", "wonyoung_look", "gaeul_ootd", "rei_fashion",
    "sieun_style", "yoon_daily", "sumin_look", "isa_ootd", "jiyeon_fashion",
    "yeonjung_style", "seola_daily", "bona_look", "exy_ootd", "soobin_fashion",
    # 30ëŒ€ ì—¬ì„± - 40ëª…
    "worklife_soyeon", "office_style_j", "career_woman_kim", "elegant_jihye",
    "chic_soojin", "modern_lady_lee", "classy_mirae", "refined_yoona",
    "sophisticated_hana", "professional_beauty", "city_girl_seoul", "urban_style_k",
    "business_chic_j", "polished_look_m", "smart_casual_y", "office_chic_kim",
    "career_style_lee", "working_mom_j", "modern_office_k", "elegant_30s_m",
    "chic_career_y", "professional_look_h", "city_style_seoul", "urban_chic_k",
    "business_look_j", "polished_style_m", "smart_office_y", "classy_30s_kim",
    "refined_career_lee", "sophisticated_office_j", "modern_working_k", "elegant_business_m",
    "chic_professional_y", "career_chic_h", "city_elegant_seoul", "urban_business_k",
    "office_elegant_j", "working_chic_m", "career_modern_y", "professional_30s_kim",
    # 40ëŒ€ ì—¬ì„± - 30ëª…
    "graceful_40s", "timeless_beauty_k", "ageless_style_j", "classic_elegance",
    "mature_chic_lee", "forever_young_kim", "elegant_midlife", "stylish_40plus",
    "refined_beauty_m", "sophisticated_40s", "graceful_lady_j", "timeless_style_k",
    "ageless_beauty_m", "classic_chic_y", "mature_elegance_h", "forever_style_seoul",
    "elegant_40plus_k", "stylish_mature_j", "refined_40s_m", "sophisticated_lady_y",
    "graceful_chic_h", "timeless_elegance_seoul", "ageless_chic_k", "classic_style_j",
    "mature_refined_m", "forever_elegant_y", "elegant_classic_h", "stylish_ageless_seoul",
    "refined_mature_k", "sophisticated_timeless_j",
    # 20ëŒ€ ë‚¨ì„± - 25ëª…
    "street_boy_kim", "urban_mens_style", "cool_guy_j", "trendy_man_lee",
    "fashion_bro_k", "style_guy_seoul", "mens_daily_look", "dapper_dude_j",
    "casual_mens_m", "hip_hop_style_k", "street_style_lee", "urban_cool_j",
    "trendy_boy_k", "fashion_guy_m", "style_dude_y", "mens_street_h",
    "dapper_style_seoul", "casual_cool_k", "hip_style_j", "street_fashion_m",
    "urban_dude_y", "trendy_cool_h", "fashion_street_seoul", "style_hip_k",
    "mens_trendy_j",
    # 30ëŒ€ ë‚¨ì„± - 15ëª…
    "gentleman_style_k", "business_man_look", "smart_casual_m", "modern_man_j",
    "mature_mens_style", "classy_guy_lee", "gentleman_look_h", "business_style_seoul",
    "smart_man_k", "modern_gentleman_j", "mature_style_m", "classy_business_y",
    "gentleman_chic_h", "business_casual_seoul", "smart_gentleman_k",
]

def generate_trendsetter_usernames(count: int) -> list:
    """Trendsetter ìœ ì €ë„¤ì„ ë™ì  ìƒì„±"""
    usernames = list(TRENDSETTER_USERNAME_BASES)
    # ë¶€ì¡±í•˜ë©´ ë²ˆí˜¸ ë¶™ì—¬ì„œ ì¶”ê°€
    idx = 0
    while len(usernames) < count:
        base = TRENDSETTER_USERNAME_BASES[idx % len(TRENDSETTER_USERNAME_BASES)]
        usernames.append(f"{base}_{len(usernames)}")
        idx += 1
    return usernames[:count]

TRENDSETTER_USERNAMES = generate_trendsetter_usernames(180)

# íŠ¸ë Œë“œì„¸í„° ë°”ì´ì˜¤ - ì—°ë ¹ëŒ€/ì„±ë³„ë³„
TRENDSETTER_BIOS_FEMALE_20 = [  # 20ëŒ€ ì—¬ì„±
    "fashion | daily",
    "ootd ğŸ“¸",
    "seoul ğŸ‡°ğŸ‡· | 20s",
    "style âœ¨ MZê°ì„±",
    "fashion lover ğŸ’•",
    "daily look | ëŒ€í•™ìƒ",
    "ğŸ“ì„œìš¸ | Y2K style",
    "âœ‰ï¸ DM for collab",
    "lifestyle | ì·¨ì¤€ìƒ",
    "fashion & beauty ğŸŒ¸",
    "ootd diary ğŸ““",
    "minimal style",
    "í™í•œ ê°ì„± âœŒï¸",
    "ìŠ¤íŠ¸ë¦¿ íŒ¨ì…˜ ğŸ”¥",
    "ìº í¼ìŠ¤ ë£© ğŸ“š",
]

TRENDSETTER_BIOS_FEMALE_30 = [  # 30ëŒ€ ì—¬ì„±
    "30ëŒ€ ì§ì¥ì¸ | daily",
    "ì›Œí‚¹ë§˜ ì¼ìƒ ğŸ’¼",
    "ì˜¤í”¼ìŠ¤ë£© ì „ë¬¸ ğŸ‘”",
    "30s fashion | ì„œìš¸",
    "career woman style",
    "modern & chic âœ¨",
    "ì§ì¥ì¸ ë°ì¼ë¦¬ ğŸ‘©â€ğŸ’¼",
    "30ëŒ€ ì—¬ìì˜ íŒ¨ì…˜ ğŸŒ·",
    "ì„¸ë ¨ëœ ì¼ìƒ ğŸ™ï¸",
    "ì¶œê·¼ë£© | í‡´ê·¼ë£© ğŸ‘ ",
    "ë¹„ì¦ˆë‹ˆìŠ¤ ìºì£¼ì–¼ ğŸ’„",
    "30ëŒ€ ë§íŒ”í™˜ì˜ ğŸ¤",
]

TRENDSETTER_BIOS_FEMALE_40 = [  # 40ëŒ€ ì—¬ì„±
    "40ëŒ€ì˜ í’ˆê²©ìˆëŠ” ì¼ìƒ",
    "elegant style | 40s",
    "timeless beauty âœ¨",
    "classic fashion ğŸŒ¹",
    "graceful 40s | seoul",
    "40ëŒ€ ì—¬ìì˜ ë©‹ ğŸ’",
    "ìš°ì•„í•œ ì¼ìƒ ğŸ€",
    "ì„¸ì›”ì„ ì´ê¸°ëŠ” ìŠ¤íƒ€ì¼",
    "í’ˆìœ„ìˆëŠ” íŒ¨ì…˜ ğŸ‘—",
    "ì—ì´ì§€ë¦¬ìŠ¤ ë·°í‹° ğŸ’«",
]

TRENDSETTER_BIOS_MALE_20 = [  # 20ëŒ€ ë‚¨ì„±
    "mens fashion ğŸ”¥",
    "street style | 20s",
    "í™í•© ê°ì„± ğŸ¤",
    "ë‚¨ì ë°ì¼ë¦¬ ğŸ‘Ÿ",
    "urban style | seoul",
    "ìŠ¤íŠ¸ë¦¿ íŒ¨ì…˜ ğŸ›¹",
    "20ëŒ€ ë‚¨ì ootd",
    "casual & cool ğŸ˜",
]

TRENDSETTER_BIOS_MALE_30 = [  # 30ëŒ€ ë‚¨ì„±
    "30ëŒ€ ë‚¨ì íŒ¨ì…˜ ğŸ‘”",
    "ì  í‹€ë§¨ ìŠ¤íƒ€ì¼ ğŸ©",
    "ë¹„ì¦ˆë‹ˆìŠ¤ ìºì£¼ì–¼ ğŸ’¼",
    "modern gentleman",
    "30s mens style",
    "í´ë˜ì‹ & ëª¨ë˜ ğŸ–¤",
]

# ê¸°ë³¸ ë°”ì´ì˜¤ (í˜¼í•©)
TRENDSETTER_BIOS = (TRENDSETTER_BIOS_FEMALE_20 + TRENDSETTER_BIOS_FEMALE_30 +
                   TRENDSETTER_BIOS_FEMALE_40 + TRENDSETTER_BIOS_MALE_20 +
                   TRENDSETTER_BIOS_MALE_30)

TRENDSETTER_CAPTIONS = [
    "",
    "#ootd",
    "âœ¨",
    "#dailylook",
    "",
    "ğŸ–¤",
    "#fashion",
    "",
    "#style",
    "",
]

# ìŠ¤íƒ€ì¼ ë° ë¶„ì„ ë°ì´í„°
DOMINANT_STYLES = ["luxury", "natural", "trendy", "colorful", "minimal"]
SUB_STYLES = ["modern", "classic", "casual", "street", "feminine", "chic", "bohemian", "preppy"]
COLOR_PALETTES = ["warm_gold", "neutral_warm", "neutral_cool", "monochrome", "pastel_pop", "earth_tone", "black_gold"]
AESTHETIC_TAGS = [
    "ìŠ¤íŠ¸ë¦¿íŒ¨ì…˜", "Y2K", "ìºì£¼ì–¼", "ë ˆì´ì–´ë“œ", "ë°ë‹˜", "ë¯¸ë‹ˆë©€", "ì˜¤ë²„ì‚¬ì´ì¦ˆ",
    "í¬ë¡­íƒ‘", "ì™€ì´ë“œíŒ¬ì¸ ", "í”Œë¦¬ì¸ ", "ë‹ˆíŠ¸", "ìì¼“", "ì½”íŠ¸ë£©", "ì›í”¼ìŠ¤",
    "ë¸”ë ˆì´ì €", "í•˜ì´ì›¨ì´ìŠ¤íŠ¸", "ë¹ˆí‹°ì§€", "ëª¨ë˜ì‹œí¬", "í˜ë¯¸ë‹Œ", "ë³´í—¤ë¯¸ì•ˆ"
]
HAIR_STYLE_TAGS = [
    "ì›¨ì´ë¸Œ", "ë ˆì´ì–´ë“œì»·", "ë‚´ì¶”ëŸ´ë¸Œë¼ìš´", "íˆí”¼íŒ", "Cì»¬", "ë³¼ë¥¨íŒ",
    "ì• ì‰¬ë¸Œë¼ìš´", "í—ˆì‰¬ì»·", "ë¡±í—¤ì–´", "ë‹¨ë°œ", "ì—¼ìƒ‰", "í•˜ì´ë¼ì´íŠ¸"
]
# ì—°ë ¹ëŒ€/ì„±ë³„ë³„ VIBES
VIBES_FEMALE_20 = [
    "í™í•˜ê³  íŠ¸ë Œë””í•œ MZì„¸ëŒ€ íŒ¨ì…˜ ì¸í”Œë£¨ì–¸ì„œ",
    "ì»¬ëŸ¬í’€í•˜ê³  ê°œì„± ë„˜ì¹˜ëŠ” Y2K ê°ì„± í¬ë¦¬ì—ì´í„°",
    "ë¯¸ë‹ˆë©€í•˜ê³  ê¹”ë”í•œ ëª¨ë˜ ì‹œí¬ ìŠ¤íƒ€ì¼",
    "ìŠ¤íŠ¸ë¦¿ê³¼ í•˜ì´íŒ¨ì…˜ì„ ë„˜ë‚˜ë“œëŠ” íŠ¸ë Œë“œì„¸í„°",
    "ëŒ€í•™ìƒ ê°ì„±ì˜ ìº í¼ìŠ¤ íŒ¨ì…˜ ì¸í”Œë£¨ì–¸ì„œ",
    "SNS íŠ¸ë Œë“œë¥¼ ì„ ë„í•˜ëŠ” 20ëŒ€ ì—¬ì„± í¬ë¦¬ì—ì´í„°",
]

VIBES_FEMALE_30 = [
    "ì„¸ë ¨ëœ 30ëŒ€ ì§ì¥ì¸ì˜ ì˜¤í”¼ìŠ¤ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸",
    "ì¼ê³¼ ì‚¶ì˜ ê· í˜•ì„ ë³´ì—¬ì£¼ëŠ” ì›Œí‚¹ë§˜ ì¸í”Œë£¨ì–¸ì„œ",
    "í”„ë¡œí˜ì…”ë„í•˜ë©´ì„œë„ íŠ¸ë Œë””í•œ 30ëŒ€ íŒ¨ì…”ë‹ˆìŠ¤íƒ€",
    "30ëŒ€ ì—¬ì„±ì˜ ì„¸ë ¨ëœ ì¼ìƒì„ ê³µìœ í•˜ëŠ” í¬ë¦¬ì—ì´í„°",
    "ë¹„ì¦ˆë‹ˆìŠ¤ ìºì£¼ì–¼ì˜ ì •ì„ì„ ë³´ì—¬ì£¼ëŠ” ì¸í”Œë£¨ì–¸ì„œ",
    "ì»¤ë¦¬ì–´ì™€ ìŠ¤íƒ€ì¼ì„ ë™ì‹œì— ì¡ì€ 30ëŒ€ ì—¬ì„±",
]

VIBES_FEMALE_40 = [
    "ê³ ê¸‰ìŠ¤ëŸ½ê³  ì„¸ë ¨ëœ ëŸ­ì…”ë¦¬ ë¬´ë“œì˜ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸",
    "ìì—°ìŠ¤ëŸ½ê³  í¸ì•ˆí•œ ë°ì¼ë¦¬ë£©ì„ ì„ ë³´ì´ëŠ” ì¸í”Œë£¨ì–¸ì„œ",
    "í’ˆê²©ìˆëŠ” 40ëŒ€ì˜ ìš°ì•„í•œ ìŠ¤íƒ€ì¼ì„ ë³´ì—¬ì£¼ëŠ” í¬ë¦¬ì—ì´í„°",
    "í´ë˜ì‹ê³¼ í˜„ëŒ€ë¥¼ ë¯¹ìŠ¤í•œ ì—ì´ì§€ë¦¬ìŠ¤ íŒ¨ì…”ë‹ˆìŠ¤íƒ€",
    "ì„¸ì›”ì„ ì´ê¸°ëŠ” ì•„ë¦„ë‹¤ì›€ì„ ë³´ì—¬ì£¼ëŠ” 40ëŒ€ ì¸í”Œë£¨ì–¸ì„œ",
    "ìš°ì•„í•˜ê³  ë‹¨ì •í•œ ì¤‘ë…„ ì—¬ì„± íŒ¨ì…˜ ë¦¬ë”",
]

VIBES_MALE_20 = [
    "ìŠ¤íŠ¸ë¦¿ íŒ¨ì…˜ì„ ì„ ë„í•˜ëŠ” 20ëŒ€ ë‚¨ì„± ì¸í”Œë£¨ì–¸ì„œ",
    "í™í•© ê°ì„±ì˜ íŠ¸ë Œë””í•œ ë‚¨ì„± í¬ë¦¬ì—ì´í„°",
    "ìºì£¼ì–¼í•˜ë©´ì„œë„ ì„¸ë ¨ëœ 20ëŒ€ ë‚¨ì ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸",
    "MZì„¸ëŒ€ ë‚¨ì„±ì˜ ë°ì¼ë¦¬ë£©ì„ ë³´ì—¬ì£¼ëŠ” ì¸í”Œë£¨ì–¸ì„œ",
]

VIBES_MALE_30 = [
    "ì  í‹€ë§¨ ìŠ¤íƒ€ì¼ì˜ 30ëŒ€ ë‚¨ì„± íŒ¨ì…”ë‹ˆìŠ¤íƒ€",
    "ë¹„ì¦ˆë‹ˆìŠ¤ ìºì£¼ì–¼ì˜ ì •ì„ì„ ë³´ì—¬ì£¼ëŠ” ì§ì¥ì¸ ì¸í”Œë£¨ì–¸ì„œ",
    "í´ë˜ì‹í•˜ë©´ì„œë„ ëª¨ë˜í•œ 30ëŒ€ ë‚¨ì„± ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸",
    "í”„ë¡œí˜ì…”ë„í•œ ì´ë¯¸ì§€ì˜ 30ëŒ€ ë‚¨ì„± í¬ë¦¬ì—ì´í„°",
]

VIBES = VIBES_FEMALE_20 + VIBES_FEMALE_30 + VIBES_FEMALE_40 + VIBES_MALE_20 + VIBES_MALE_30

# Expert ì´ë¯¸ì§€ ë¶„ì„ ë°ì´í„°
SPECIALTIES = ["ì—¼ìƒ‰", "íŒ", "ì»¤íŠ¸", "í´ë¦¬ë‹‰", "ë‘í”¼ì¼€ì–´", "ì›¨ë”©í—¤ì–´", "ë‚¨ì„±ì»¤íŠ¸", "íƒˆëª¨ì¼€ì–´"]
TECHNIQUES = ["Cì»¬íŒ", "íˆí”¼íŒ", "ë³¼ë¥¨íŒ", "ë ˆì´ì–´ë“œì»·", "ì• ì‰¬ì—¼ìƒ‰", "í•˜ì´í†¤ì—¼ìƒ‰", "í´ë¦¬ë‹‰íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸", "ë‘í”¼ìŠ¤ì¼€ì¼ë§"]
CLIENT_HAIR_TYPES = ["ì›¨ì´ë¸Œ", "ìŠ¤íŠ¸ë ˆì´íŠ¸", "ë³¼ë¥¨íŒ", "Cì»¬", "íˆí”¼íŒ", "ë ˆì´ì–´ë“œ", "ë‹¨ë°œ", "ë¡±í—¤ì–´"]
COLOR_SPECIALTIES_LIST = ["ì• ì‰¬", "ë¸Œë¼ìš´", "í•˜ì´í†¤", "ë¡œìš°í†¤", "ê·¸ë ˆì´", "í•‘í¬", "ë ˆë“œ", "ë² ì´ì§€"]
WORK_ENVIRONMENTS = ["salon", "home_salon", "freelance", "academy"]


def generate_post_id():
    """Instagram ìŠ¤íƒ€ì¼ ê²Œì‹œë¬¼ ID ìƒì„±"""
    chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_-"
    return "".join(random.choices(chars, k=11))


def generate_permalink(username: str, post_id: str) -> str:
    """Instagram permalink ìƒì„±"""
    return f"https://www.instagram.com/reel/{post_id}/"


def generate_media_url(post_id: str) -> str:
    """Instagram media URL ìƒì„± (ì‹¤ì œë¡œëŠ” CDN URL)"""
    return f"https://scontent.cdninstagram.com/v/t51.2885-15/{post_id}.jpg"


def generate_timestamp(days_ago: int) -> str:
    """ISO 8601 í˜•ì‹ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±"""
    dt = datetime.now() - timedelta(days=days_ago)
    return dt.strftime("%Y-%m-%dT%H:%M:%S+0000")


def generate_expert_posts(num_posts: int = 10, is_fake: bool = False) -> list:
    """
    Expertí˜• ì¸í”Œë£¨ì–¸ì„œì˜ ë¦´ìŠ¤ ê²Œì‹œë¬¼ ìƒì„±

    Args:
        num_posts: ê²Œì‹œë¬¼ ìˆ˜
        is_fake: í—ˆìˆ˜ ê³„ì • ì—¬ë¶€ (views ëŒ€ë¹„ likes/comments ë¹„ìœ¨ ì¡°ì‘)

    Returns:
        ê²Œì‹œë¬¼ ë¦¬ìŠ¤íŠ¸ (views í•„ë“œ í¬í•¨)
    """
    posts = []
    for i in range(num_posts):
        post_id = generate_post_id()

        # ì¡°íšŒìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì¢‹ì•„ìš”/ëŒ“ê¸€ ìƒì„± (ì •ìƒ ë¹„ìœ¨: likes 2-8%, comments 0.1-1%)
        views = random.randint(10000, 80000)

        if is_fake:
            # í—ˆìˆ˜ ê³„ì •: ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ì¢‹ì•„ìš” ë¹„ìœ¨ (15-30%)
            likes = int(views * random.uniform(0.15, 0.30))
            comments = int(views * random.uniform(0.03, 0.08))
        else:
            # ì •ìƒ ê³„ì •: ì ì • ë¹„ìœ¨
            likes = int(views * random.uniform(0.02, 0.08))
            comments = int(views * random.uniform(0.001, 0.01))

        posts.append({
            "caption": random.choice(EXPERT_CAPTIONS),
            "views": views,
            "likes": likes,
            "comments": comments,
            "media_type": "VIDEO",  # ë¦´ìŠ¤
            "timestamp": generate_timestamp(i * random.randint(2, 5)),
            "media_url": generate_media_url(post_id),
            "permalink": generate_permalink("expert", post_id)
        })
    return posts


def generate_trendsetter_posts(num_posts: int = 10, is_fake: bool = False, is_viewbot: bool = False) -> list:
    """
    Trendsetterí˜• ì¸í”Œë£¨ì–¸ì„œì˜ ë¦´ìŠ¤ ê²Œì‹œë¬¼ ìƒì„±

    Args:
        num_posts: ê²Œì‹œë¬¼ ìˆ˜
        is_fake: í—ˆìˆ˜ ê³„ì • ì—¬ë¶€ (ì¢‹ì•„ìš” êµ¬ë§¤ ì˜ì‹¬)
        is_viewbot: ë·°ë´‡ ê³„ì • ì—¬ë¶€ (ì¡°íšŒìˆ˜ ëŒ€ë¹„ ì°¸ì—¬ìœ¨ ê·¹íˆ ë‚®ìŒ)

    Returns:
        ê²Œì‹œë¬¼ ë¦¬ìŠ¤íŠ¸ (views í•„ë“œ í¬í•¨)
    """
    posts = []
    for i in range(num_posts):
        post_id = generate_post_id()

        # íŠ¸ë Œë“œì„¸í„°ëŠ” ì¡°íšŒìˆ˜ê°€ ë†’ìŒ
        views = random.randint(50000, 500000)

        if is_viewbot:
            # ë·°ë´‡ ê³„ì •: ì¡°íšŒìˆ˜ëŠ” ë†’ì§€ë§Œ ì°¸ì—¬ìœ¨ ê·¹íˆ ë‚®ìŒ (likes < 1%)
            likes = int(views * random.uniform(0.001, 0.008))
            comments = int(views * random.uniform(0.0001, 0.0005))
        elif is_fake:
            # ì¢‹ì•„ìš” êµ¬ë§¤ ê³„ì •: ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ì¢‹ì•„ìš” ë¹„ìœ¨ (20-35%)
            likes = int(views * random.uniform(0.20, 0.35))
            comments = int(views * random.uniform(0.04, 0.10))
        else:
            # ì •ìƒ ê³„ì •: íŠ¸ë Œë“œì„¸í„° ì ì • ë¹„ìœ¨ (likes 3-12%, comments 0.3-2%)
            likes = int(views * random.uniform(0.03, 0.12))
            comments = int(views * random.uniform(0.003, 0.02))

        posts.append({
            "caption": random.choice(TRENDSETTER_CAPTIONS),
            "views": views,
            "likes": likes,
            "comments": comments,
            "media_type": "VIDEO",  # ë¦´ìŠ¤
            "timestamp": generate_timestamp(i * random.randint(1, 3)),
            "media_url": generate_media_url(post_id),
            "permalink": generate_permalink("trendsetter", post_id)
        })
    return posts


def generate_expert_text_analysis(bio: str, captions: list) -> dict:
    """
    Expertí˜• í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ ìƒì„± (Primary ë¶„ì„)

    ExpertëŠ” bioì™€ captionì— ì •ë³´ê°€ í’ë¶€í•˜ë¯€ë¡œ í…ìŠ¤íŠ¸ ë¶„ì„ì´ í•µì‹¬.
    - bioì—ì„œ ìê²©ì¦, ê²½ë ¥, ì „ë¬¸ ë¶„ì•¼ ì¶”ì¶œ
    - captionì—ì„œ ì‹œìˆ  í‚¤ì›Œë“œ, ë ˆì‹œí”¼, ê¸°ë²• ì¶”ì¶œ
    """
    # bioì—ì„œ ì „ë¬¸ ë¶„ì•¼ ì¶”ì¶œ
    specialties_from_bio = []
    certifications = []

    bio_text = bio.lower()
    for specialty in SPECIALTIES:
        if specialty in bio_text or specialty in bio:
            specialties_from_bio.append(specialty)

    # ìê²©ì¦/ê²½ë ¥ í‚¤ì›Œë“œ
    cert_keywords = ["ì›ì¥", "ë””ë ‰í„°", "ë…„ì°¨", "ê²½ë ¥", "ìê²©ì¦", "êµìœ¡", "ì•„ì¹´ë°ë¯¸"]
    for kw in cert_keywords:
        if kw in bio:
            certifications.append(kw)

    # captionì—ì„œ ì‹œìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ
    techniques_from_caption = []
    all_captions = " ".join(captions)
    for tech in TECHNIQUES:
        if tech in all_captions:
            techniques_from_caption.append(tech)

    if not techniques_from_caption:
        techniques_from_caption = random.sample(TECHNIQUES, k=random.randint(2, 4))

    return {
        "analysis_type": "text_primary",  # í…ìŠ¤íŠ¸ ë¶„ì„ì´ ì£¼ë ¥
        "specialties_from_bio": specialties_from_bio if specialties_from_bio else random.sample(SPECIALTIES, k=2),
        "certifications_detected": certifications,
        "techniques_from_caption": techniques_from_caption,
        "caption_detail_level": "high",  # ExpertëŠ” captionì´ ìƒì„¸í•¨
        "text_confidence": round(random.uniform(0.8, 0.95), 2)
    }


def generate_expert_image_analysis(bio: str) -> dict:
    """
    Expertí˜• ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ìƒì„± (Secondary ë¶„ì„ - ê²€ì¦/ë³´ì™„ìš©)

    ExpertëŠ” í…ìŠ¤íŠ¸ ì •ë³´ê°€ í’ë¶€í•˜ë¯€ë¡œ ì´ë¯¸ì§€ ë¶„ì„ì€ ë³´ì¡°ì  ì—­í• :
    - bioì—ì„œ ì–¸ê¸‰ëœ ì „ë¬¸ ë¶„ì•¼ê°€ ì‹¤ì œ ì‹œìˆ  ì´ë¯¸ì§€ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦
    - í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì¶”ê°€ ì „ë¬¸ ë¶„ì•¼ ë°œê²¬
    """
    # bioì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ verified_specialties ìƒì„±
    verified = []
    additional = []

    bio_lower = bio.lower()
    for specialty in SPECIALTIES:
        if specialty in bio_lower or specialty in bio:
            verified.append(specialty)
        elif random.random() < 0.3:
            additional.append(specialty)

    if not verified:
        verified = random.sample(SPECIALTIES, k=random.randint(1, 3))
    if not additional:
        additional = random.sample([s for s in SPECIALTIES if s not in verified], k=random.randint(0, 2))

    return {
        "analysis_type": "image_secondary",  # ì´ë¯¸ì§€ ë¶„ì„ì€ ë³´ì¡°
        "verified_specialties": verified[:3],  # bio ì •ë³´ ê²€ì¦ë¨
        "additional_specialties": additional[:2],  # ì´ë¯¸ì§€ì—ì„œ ì¶”ê°€ ë°œê²¬
        "signature_techniques": random.sample(TECHNIQUES, k=random.randint(2, 4)),
        "client_hair_types": random.sample(CLIENT_HAIR_TYPES, k=random.randint(2, 4)),
        "color_specialties": random.sample(COLOR_SPECIALTIES_LIST, k=random.randint(2, 3)),
        "work_environment": random.choice(WORK_ENVIRONMENTS),
        "content_quality_score": round(random.uniform(0.7, 0.95), 2),
        "expertise_confidence": round(random.uniform(0.7, 0.95), 2)
    }


def generate_trendsetter_text_analysis(bio: str, captions: list) -> dict:
    """
    Trendsetterí˜• í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ ìƒì„± (Secondary ë¶„ì„ - ë³´ì¡°)

    TrendsetterëŠ” bioì™€ captionì´ ê±°ì˜ ë¹„ì–´ìˆìœ¼ë¯€ë¡œ í…ìŠ¤íŠ¸ ë¶„ì„ì€ ë³´ì¡°ì  ì—­í• :
    - bioê°€ ê°„ë‹¨í•˜ë¯€ë¡œ ì¶”ì¶œ ê°€ëŠ¥í•œ ì •ë³´ ì œí•œì 
    - captionë„ í•´ì‹œíƒœê·¸ ìœ„ì£¼ë¡œ ê°„ëµí•¨
    - í…ìŠ¤íŠ¸ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” ì •ë³´ê°€ ì ì–´ ì‹ ë¢°ë„ ë‚®ìŒ
    """
    # bioì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ í‚¤ì›Œë“œ (ë§¤ìš° ì œí•œì )
    keywords_from_bio = []
    style_hints = []

    bio_lower = bio.lower()
    style_keywords = ["fashion", "style", "ootd", "daily", "minimal", "lifestyle"]
    for kw in style_keywords:
        if kw in bio_lower:
            keywords_from_bio.append(kw)

    # captionì—ì„œ í•´ì‹œíƒœê·¸ ì¶”ì¶œ (ëŒ€ë¶€ë¶„ ê°„ë‹¨í•¨)
    hashtags = []
    for caption in captions:
        if "#" in caption:
            tags = [word.strip() for word in caption.split() if word.startswith("#")]
            hashtags.extend(tags)

    return {
        "analysis_type": "text_secondary",  # í…ìŠ¤íŠ¸ ë¶„ì„ì€ ë³´ì¡°
        "keywords_from_bio": keywords_from_bio if keywords_from_bio else ["lifestyle"],
        "hashtags_from_caption": list(set(hashtags))[:5],
        "caption_detail_level": "low",  # TrendsetterëŠ” captionì´ ê°„ëµí•¨
        "extractable_info": "minimal",  # ì¶”ì¶œ ê°€ëŠ¥í•œ ì •ë³´ ì œí•œì 
        "text_confidence": round(random.uniform(0.2, 0.5), 2)  # ë‚®ì€ ì‹ ë¢°ë„
    }


def generate_trendsetter_image_analysis() -> dict:
    """
    Trendsetterí˜• ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ìƒì„± (Primary ë¶„ì„ - í•µì‹¬)

    TrendsetterëŠ” í…ìŠ¤íŠ¸ ì •ë³´ê°€ ë¶€ì¡±í•˜ë¯€ë¡œ ì´ë¯¸ì§€ ë¶„ì„ì´ í•µì‹¬:
    - ìŠ¤íƒ€ì¼, ì»¬ëŸ¬, ë¯¸í•™ì  íƒœê·¸ëŠ” ì´ë¯¸ì§€ì—ì„œ ì§ì ‘ ì¶”ì¶œ
    - í—¤ì–´ ìŠ¤íƒ€ì¼ë„ ì´ë¯¸ì§€ ë¶„ì„ìœ¼ë¡œë§Œ íŒŒì•… ê°€ëŠ¥
    - ë¸Œëœë“œ ë§¤ì¹­ì„ ìœ„í•œ ëª¨ë“  í•µì‹¬ ì •ë³´ê°€ ì´ë¯¸ì§€ì—ì„œ ë„ì¶œë¨
    """
    return {
        "analysis_type": "image_primary",  # ì´ë¯¸ì§€ ë¶„ì„ì´ ì£¼ë ¥
        "dominant_style": random.choice(DOMINANT_STYLES),
        "sub_styles": random.sample(SUB_STYLES, k=2),
        "color_palette": random.choice(COLOR_PALETTES),
        "aesthetic_tags": random.sample(AESTHETIC_TAGS, k=5),
        "hair_style_tags": random.sample(HAIR_STYLE_TAGS, k=random.randint(2, 4)),
        "vibe": random.choice(VIBES),
        "professionalism_score": round(random.uniform(0.3, 0.6), 2),
        "trend_relevance_score": round(random.uniform(0.8, 0.95), 2),
        "image_confidence": round(random.uniform(0.85, 0.98), 2)  # ë†’ì€ ì‹ ë¢°ë„
    }


def generate_expert_influencer(username: str, index: int) -> dict:
    """
    Expertí˜• ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ìƒì„±

    ë¶„ì„ ì „ëµ:
    - text_analysis: PRIMARY (bio/captionì´ í’ë¶€í•˜ë¯€ë¡œ í•µì‹¬ ì •ë³´ì›)
    - image_analysis: SECONDARY (í…ìŠ¤íŠ¸ ì •ë³´ ê²€ì¦ ë° ë³´ì™„ìš©)
    """
    bio = EXPERT_BIOS[index % len(EXPERT_BIOS)]
    posts = generate_expert_posts(num_posts=10)
    captions = [post["caption"] for post in posts]

    return {
        "username": username,
        "influencer_type": "expert",
        "followers": random.randint(30000, 150000),
        "bio": bio,
        "media_count": random.randint(200, 800),
        "recent_posts": posts,
        "audience_countries": {
            "KR": round(random.uniform(0.85, 0.95), 2),
            "US": round(random.uniform(0.01, 0.05), 2),
            "JP": round(random.uniform(0.01, 0.05), 2),
            "OTHER": round(random.uniform(0.01, 0.05), 2)
        },
        "avg_upload_interval_days": round(random.uniform(2.0, 5.0), 1),
        "analysis_strategy": {
            "primary": "text",
            "secondary": "image",
            "reason": "ExpertëŠ” bioì™€ captionì— ì „ë¬¸ ì •ë³´ê°€ í’ë¶€í•¨"
        },
        "text_analysis": generate_expert_text_analysis(bio, captions),
        "image_analysis": generate_expert_image_analysis(bio)
    }


def generate_trendsetter_influencer(username: str, index: int) -> dict:
    """
    Trendsetterí˜• ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ìƒì„±

    ë¶„ì„ ì „ëµ:
    - image_analysis: PRIMARY (bio/captionì´ ë¹„ì–´ìˆì–´ ì´ë¯¸ì§€ì—ì„œ ì •ë³´ ì¶”ì¶œ)
    - text_analysis: SECONDARY (í•´ì‹œíƒœê·¸ ë“± ë³´ì¡° ì •ë³´ë§Œ ì¶”ì¶œ)
    """
    bio = TRENDSETTER_BIOS[index % len(TRENDSETTER_BIOS)]
    posts = generate_trendsetter_posts(num_posts=10)
    captions = [post["caption"] for post in posts]

    return {
        "username": username,
        "influencer_type": "trendsetter",
        "followers": random.randint(100000, 500000),
        "bio": bio,
        "media_count": random.randint(300, 1000),
        "recent_posts": posts,
        "audience_countries": {
            "KR": round(random.uniform(0.70, 0.85), 2),
            "US": round(random.uniform(0.05, 0.10), 2),
            "JP": round(random.uniform(0.03, 0.08), 2),
            "OTHER": round(random.uniform(0.05, 0.10), 2)
        },
        "avg_upload_interval_days": round(random.uniform(1.0, 3.0), 1),
        "analysis_strategy": {
            "primary": "image",
            "secondary": "text",
            "reason": "TrendsetterëŠ” bio/captionì´ ê°„ëµí•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„ì´ í•µì‹¬"
        },
        "text_analysis": generate_trendsetter_text_analysis(bio, captions),
        "image_analysis": generate_trendsetter_image_analysis()
    }


def generate_raw_data(num_experts: int = 50, num_trendsetters: int = 50, fake_ratio: float = 0.1) -> dict:
    """
    í¬ë¡¤ëŸ¬ í˜•ì‹ì˜ raw ë°ì´í„° ìƒì„± (ë¶„ë¥˜/ë¶„ì„ ì—†ìŒ)

    ì‹¤ì œ Instagram APIì—ì„œ ìˆ˜ì§‘í•˜ëŠ” í˜•íƒœì™€ ë™ì¼
    - influencer_type, analysis_strategy, text_analysis, image_analysis ì—†ìŒ
    - Processorì—ì„œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•íƒœ

    Args:
        num_experts: Expert ì¸í”Œë£¨ì–¸ì„œ ìˆ˜
        num_trendsetters: Trendsetter ì¸í”Œë£¨ì–¸ì„œ ìˆ˜
        fake_ratio: í—ˆìˆ˜ ê³„ì • ë¹„ìœ¨ (ê¸°ë³¸ 10%)

    Returns:
        raw ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    influencers = []

    # í—ˆìˆ˜ ê³„ì • ìˆ˜ ê³„ì‚°
    num_fake_experts = int(num_experts * fake_ratio)
    num_fake_trendsetters = int(num_trendsetters * fake_ratio)
    num_viewbot_trendsetters = int(num_trendsetters * fake_ratio / 2)

    # Expert ìƒì„± (ì¼ë¶€ í—ˆìˆ˜) - raw í˜•ì‹
    for i, username in enumerate(EXPERT_USERNAMES[:num_experts]):
        is_fake = i < num_fake_experts
        bio = EXPERT_BIOS[i % len(EXPERT_BIOS)]
        posts = generate_expert_posts(num_posts=10, is_fake=is_fake)

        influencer = {
            "username": username,
            "followers": random.randint(30000, 150000),
            "bio": bio,
            "media_count": random.randint(200, 800),
            "recent_posts": posts,
            "audience_countries": {
                "KR": round(random.uniform(0.85, 0.95), 2),
                "US": round(random.uniform(0.01, 0.05), 2),
                "JP": round(random.uniform(0.01, 0.05), 2),
                "OTHER": round(random.uniform(0.01, 0.05), 2)
            },
            "avg_upload_interval_days": round(random.uniform(2.0, 5.0), 1)
        }
        if is_fake:
            influencer["_test_label"] = "fake_likes"
        influencers.append(influencer)

    # Trendsetter ìƒì„± (ì¼ë¶€ í—ˆìˆ˜/ë·°ë´‡) - raw í˜•ì‹
    for i, username in enumerate(TRENDSETTER_USERNAMES[:num_trendsetters]):
        is_viewbot = i < num_viewbot_trendsetters
        is_fake = num_viewbot_trendsetters <= i < (num_viewbot_trendsetters + num_fake_trendsetters)

        bio = TRENDSETTER_BIOS[i % len(TRENDSETTER_BIOS)]
        posts = generate_trendsetter_posts(num_posts=10, is_fake=is_fake, is_viewbot=is_viewbot)

        influencer = {
            "username": username,
            "followers": random.randint(100000, 500000),
            "bio": bio,
            "media_count": random.randint(300, 1000),
            "recent_posts": posts,
            "audience_countries": {
                "KR": round(random.uniform(0.70, 0.85), 2),
                "US": round(random.uniform(0.05, 0.10), 2),
                "JP": round(random.uniform(0.03, 0.08), 2),
                "OTHER": round(random.uniform(0.05, 0.10), 2)
            },
            "avg_upload_interval_days": round(random.uniform(1.0, 3.0), 1)
        }

        if is_viewbot:
            influencer["_test_label"] = "viewbot"
        elif is_fake:
            influencer["_test_label"] = "fake_likes"

        influencers.append(influencer)

    return {
        "influencers": influencers,
        "metadata": {
            "crawled_at": datetime.now().isoformat(),
            "total_count": len(influencers),
            "posts_per_influencer": 10,
            "status": "raw",
            "note": "í¬ë¡¤ëŸ¬ì—ì„œ ìˆ˜ì§‘í•œ raw ë°ì´í„° (Processorì—ì„œ ë¶„ë¥˜/ë¶„ì„ í•„ìš”)"
        }
    }


def get_fis_score_and_verdict(category: str) -> tuple:
    """
    ë‹¤ì–‘í•œ FIS ì ìˆ˜ ë¶„í¬ ìƒì„±

    ë¶„í¬:
    - ì‹ ë¢° ê°€ëŠ¥ (80-98): 60%
    - ì£¼ì˜ í•„ìš” (60-79): 25%
    - ìœ„í—˜ (40-59): 15%
    """
    if category == 'high':  # ì‹ ë¢° ê°€ëŠ¥
        score = round(random.uniform(80, 98), 1)
        verdict = "ì‹ ë¢° ê°€ëŠ¥"
    elif category == 'medium':  # ì£¼ì˜ í•„ìš”
        score = round(random.uniform(60, 79), 1)
        verdict = "ì£¼ì˜ í•„ìš”"
    else:  # low - ìœ„í—˜
        score = round(random.uniform(40, 59), 1)
        verdict = "ìœ„í—˜"
    return score, verdict


def get_random_fis_category() -> str:
    """FIS ì¹´í…Œê³ ë¦¬ ëœë¤ ì„ íƒ (ë¶„í¬ì— ë”°ë¼)"""
    r = random.random()
    if r < 0.60:
        return 'high'
    elif r < 0.85:
        return 'medium'
    else:
        return 'low'


def determine_target_demographics(index: int, total: int, inf_type: str) -> dict:
    """
    ì¸í”Œë£¨ì–¸ì„œì˜ íƒ€ê²Ÿ ì—°ë ¹ëŒ€/ì„±ë³„ ê²°ì •

    Expert:
    - 20ëŒ€ ì—¬ì„± íƒ€ê²Ÿ: 30%
    - 30ëŒ€ ì—¬ì„± íƒ€ê²Ÿ: 25%
    - 40ëŒ€ ì—¬ì„± íƒ€ê²Ÿ: 15%
    - ë‚¨ì„± íƒ€ê²Ÿ: 20%
    - ìœ ë‹ˆì„¹ìŠ¤(ë‘í”¼/íƒˆëª¨): 10%

    Trendsetter:
    - 20ëŒ€ ì—¬ì„±: 35%
    - 30ëŒ€ ì—¬ì„±: 25%
    - 40ëŒ€ ì—¬ì„±: 15%
    - 20ëŒ€ ë‚¨ì„±: 15%
    - 30ëŒ€ ë‚¨ì„±: 10%
    """
    r = random.random()

    if inf_type == 'expert':
        if r < 0.30:
            return {'target_gender': 'female', 'target_age': '20ëŒ€'}
        elif r < 0.55:
            return {'target_gender': 'female', 'target_age': '30ëŒ€'}
        elif r < 0.70:
            return {'target_gender': 'female', 'target_age': '40ëŒ€'}
        elif r < 0.90:
            return {'target_gender': 'male', 'target_age': random.choice(['20ëŒ€', '30ëŒ€'])}
        else:
            return {'target_gender': 'unisex', 'target_age': random.choice(['30ëŒ€', '40ëŒ€'])}
    else:  # trendsetter
        if r < 0.35:
            return {'target_gender': 'female', 'target_age': '20ëŒ€'}
        elif r < 0.60:
            return {'target_gender': 'female', 'target_age': '30ëŒ€'}
        elif r < 0.75:
            return {'target_gender': 'female', 'target_age': '40ëŒ€'}
        elif r < 0.90:
            return {'target_gender': 'male', 'target_age': '20ëŒ€'}
        else:
            return {'target_gender': 'male', 'target_age': '30ëŒ€'}


def get_mood_for_demographics(target_gender: str, target_age: str) -> str:
    """íƒ€ê²Ÿ ì¸êµ¬í†µê³„ì— ë§ëŠ” ë¬´ë“œ ì„ íƒ"""
    moods = {
        ('female', '20ëŒ€'): ['íŠ¸ë Œë””í•œ', 'í™í•œ', 'Y2K ê°ì„±ì˜', 'ì»¬ëŸ¬í’€í•œ', 'ìŠ¤íŠ¸ë¦¿í•œ', 'ìºì£¼ì–¼í•œ'],
        ('female', '30ëŒ€'): ['ì„¸ë ¨ëœ', 'ëª¨ë˜í•œ', 'í”„ë¡œí˜ì…”ë„í•œ', 'ìš°ì•„í•œ', 'ì‹œí¬í•œ', 'í´ë˜ì‹œí•œ'],
        ('female', '40ëŒ€'): ['ê³ ê¸‰ìŠ¤ëŸ¬ìš´', 'ìš°ì•„í•œ', 'í´ë˜ì‹í•œ', 'í’ˆê²©ìˆëŠ”', 'ë‹¨ì •í•œ', 'ì„¸ë ¨ëœ'],
        ('male', '20ëŒ€'): ['í™í•œ', 'ìŠ¤íŠ¸ë¦¿í•œ', 'ìºì£¼ì–¼í•œ', 'íŠ¸ë Œë””í•œ', 'ì¿¨í•œ', 'ëŒ„ë””í•œ'],
        ('male', '30ëŒ€'): ['ëŒ„ë””í•œ', 'í”„ë¡œí˜ì…”ë„í•œ', 'í´ë˜ì‹í•œ', 'ëª¨ë˜í•œ', 'ì„¸ë ¨ëœ', 'ì  í‹€í•œ'],
        ('unisex', '30ëŒ€'): ['ì „ë¬¸ì ì¸', 'ì‹ ë¢°ê° ìˆëŠ”', 'í´ë¦¬ë‹‰í•œ', 'ì¼€ì–´ ì „ë¬¸'],
        ('unisex', '40ëŒ€'): ['ì „ë¬¸ì ì¸', 'ì¼€ì–´ ì „ë¬¸', 'í´ë¦¬ë‹‰í•œ', 'ì‹ ë¢°ê° ìˆëŠ”'],
    }
    key = (target_gender, target_age)
    return random.choice(moods.get(key, ['íŠ¸ë Œë””í•œ', 'ì„¸ë ¨ëœ', 'ê³ ê¸‰ìŠ¤ëŸ¬ìš´']))


def generate_processed_data(num_experts: int = 70, num_trendsetters: int = 80) -> dict:
    """
    Processorì—ì„œ ì²˜ë¦¬ëœ í˜•íƒœì˜ ë°ì´í„° ìƒì„± (ë¶„ë¥˜/ë¶„ì„ ì™„ë£Œ)

    ë‹¤ì–‘í•œ FIS ë¶„í¬:
    - ì‹ ë¢° ê°€ëŠ¥ (80-98): 60%
    - ì£¼ì˜ í•„ìš” (60-79): 25%
    - ìœ„í—˜ (40-59): 15%

    Args:
        num_experts: Expert ì¸í”Œë£¨ì–¸ì„œ ìˆ˜ (ê¸°ë³¸ 70ëª…)
        num_trendsetters: Trendsetter ì¸í”Œë£¨ì–¸ì„œ ìˆ˜ (ê¸°ë³¸ 80ëª…)

    Returns:
        ì²˜ë¦¬ëœ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    influencers = []

    # í†µê³„ ì¶”ì 
    stats = {
        'fis_high': 0, 'fis_medium': 0, 'fis_low': 0,
        'female_20': 0, 'female_30': 0, 'female_40': 0,
        'male_20': 0, 'male_30': 0, 'unisex': 0
    }

    # Expert ìƒì„± - ë‹¤ì–‘í•œ íƒ€ê²Ÿê³¼ FIS ë¶„í¬
    for i, username in enumerate(EXPERT_USERNAMES[:num_experts]):
        # íƒ€ê²Ÿ ì¸êµ¬í†µê³„ ê²°ì •
        demographics = determine_target_demographics(i, num_experts, 'expert')
        target_gender = demographics['target_gender']
        target_age = demographics['target_age']

        # í†µê³„ ì—…ë°ì´íŠ¸
        if target_gender == 'unisex':
            stats['unisex'] += 1
        else:
            stats[f'{target_gender}_{target_age[:2]}'] += 1

        # ë°”ì´ì˜¤ ì„ íƒ (íƒ€ê²Ÿì— ë§ê²Œ)
        if target_gender == 'male':
            bio = random.choice(EXPERT_BIOS_MALE)
        elif target_age == '40ëŒ€' or target_age == '30ëŒ€':
            bio = random.choice(EXPERT_BIOS_FEMALE_MATURE)
        elif target_gender == 'unisex':
            bio = random.choice(EXPERT_BIOS_SCALP)
        else:
            bio = random.choice(EXPERT_BIOS_FEMALE_YOUNG)

        posts = generate_expert_posts(num_posts=10, is_fake=False)
        captions = [post["caption"] for post in posts]

        # ë‹¤ì–‘í•œ FIS ì ìˆ˜ ë¶„í¬
        fis_category = get_random_fis_category()
        fis_score, fis_verdict = get_fis_score_and_verdict(fis_category)
        stats[f'fis_{fis_category}'] += 1

        # ë¬´ë“œ ê²°ì •
        main_mood = get_mood_for_demographics(target_gender, target_age)

        influencer = {
            "username": username,
            "influencer_type": "expert",
            "followers": random.randint(30000, 200000),
            "bio": bio,
            "classification_confidence": round(random.uniform(0.85, 1.0), 2),
            "analysis_strategy": {
                "primary": "text",
                "secondary": "image",
                "reason": "ExpertëŠ” bioì™€ captionì— ì „ë¬¸ ì •ë³´ê°€ í’ë¶€í•¨"
            },
            "text_analysis": generate_expert_text_analysis(bio, captions),
            "image_analysis": {
                **generate_expert_image_analysis(bio),
                "target_gender": target_gender,
                "target_age": target_age,
                "main_mood": main_mood,
            },
            "fis": {
                "score": fis_score,
                "verdict": fis_verdict
            }
        }
        influencers.append(influencer)

    # Trendsetter ìƒì„± - ë‹¤ì–‘í•œ íƒ€ê²Ÿê³¼ FIS ë¶„í¬
    for i, username in enumerate(TRENDSETTER_USERNAMES[:num_trendsetters]):
        # íƒ€ê²Ÿ ì¸êµ¬í†µê³„ ê²°ì •
        demographics = determine_target_demographics(i, num_trendsetters, 'trendsetter')
        target_gender = demographics['target_gender']
        target_age = demographics['target_age']

        # í†µê³„ ì—…ë°ì´íŠ¸
        if target_gender == 'unisex':
            stats['unisex'] += 1
        else:
            key = f'{target_gender}_{target_age[:2]}'
            if key in stats:
                stats[key] += 1

        # ë°”ì´ì˜¤ ì„ íƒ (íƒ€ê²Ÿì— ë§ê²Œ)
        if target_gender == 'male':
            if target_age == '30ëŒ€':
                bio = random.choice(TRENDSETTER_BIOS_MALE_30)
            else:
                bio = random.choice(TRENDSETTER_BIOS_MALE_20)
        elif target_age == '40ëŒ€':
            bio = random.choice(TRENDSETTER_BIOS_FEMALE_40)
        elif target_age == '30ëŒ€':
            bio = random.choice(TRENDSETTER_BIOS_FEMALE_30)
        else:
            bio = random.choice(TRENDSETTER_BIOS_FEMALE_20)

        posts = generate_trendsetter_posts(num_posts=10, is_fake=False, is_viewbot=False)
        captions = [post["caption"] for post in posts]

        # ë‹¤ì–‘í•œ FIS ì ìˆ˜ ë¶„í¬
        fis_category = get_random_fis_category()
        fis_score, fis_verdict = get_fis_score_and_verdict(fis_category)
        stats[f'fis_{fis_category}'] += 1

        # ë¬´ë“œì™€ ë°”ì´ë¸Œ ê²°ì •
        main_mood = get_mood_for_demographics(target_gender, target_age)

        # ë°”ì´ë¸Œ ì„ íƒ (ì—°ë ¹ëŒ€/ì„±ë³„ì— ë§ê²Œ)
        if target_gender == 'male':
            if target_age == '30ëŒ€':
                vibe = random.choice(VIBES_MALE_30)
            else:
                vibe = random.choice(VIBES_MALE_20)
        elif target_age == '40ëŒ€':
            vibe = random.choice(VIBES_FEMALE_40)
        elif target_age == '30ëŒ€':
            vibe = random.choice(VIBES_FEMALE_30)
        else:
            vibe = random.choice(VIBES_FEMALE_20)

        influencer = {
            "username": username,
            "influencer_type": "trendsetter",
            "followers": random.randint(50000, 500000),
            "bio": bio,
            "classification_confidence": round(random.uniform(0.85, 1.0), 2),
            "analysis_strategy": {
                "primary": "image",
                "secondary": "text",
                "reason": "TrendsetterëŠ” bio/captionì´ ê°„ëµí•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„ì´ í•µì‹¬"
            },
            "text_analysis": generate_trendsetter_text_analysis(bio, captions),
            "image_analysis": {
                **generate_trendsetter_image_analysis(),
                "target_gender": target_gender,
                "target_age": target_age,
                "main_mood": main_mood,
                "vibe": vibe,
            },
            "fis": {
                "score": fis_score,
                "verdict": fis_verdict
            }
        }

        influencers.append(influencer)

    return {
        "influencers": influencers,
        "metadata": {
            "processed_at": datetime.now().isoformat(),
            "total_count": len(influencers),
            "expert_count": num_experts,
            "trendsetter_count": num_trendsetters,
            "status": "processed",
            "schema_version": "5.0",
            "note": "ë‹¤ì–‘í•œ FIS ë¶„í¬ì™€ íƒ€ê²Ÿ ì¸êµ¬í†µê³„ë¥¼ í¬í•¨í•œ í™•ì¥ ë°ì´í„°",
            "raw_data_ref": "influencers_raw.json",
            "statistics": stats
        }
    }


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    data_dir = Path(__file__).parent.parent / "data"
    data_dir.mkdir(parents=True, exist_ok=True)

    # ì„¤ì • (300ëª… ë°ì´í„°ì…‹)
    NUM_EXPERTS = 120
    NUM_TRENDSETTERS = 180

    # 1. Raw ë°ì´í„° ìƒì„± (í¬ë¡¤ëŸ¬ í˜•ì‹)
    print("=" * 60)
    print("1. Raw ë°ì´í„° ìƒì„± (í¬ë¡¤ëŸ¬ í˜•ì‹)")
    print("=" * 60)

    raw_data = generate_raw_data(num_experts=NUM_EXPERTS, num_trendsetters=NUM_TRENDSETTERS)
    raw_path = data_dir / "influencers_raw.json"

    with open(raw_path, 'w', encoding='utf-8') as f:
        json.dump(raw_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… Raw ë°ì´í„° ìƒì„± ì™„ë£Œ: {raw_path}")
    print(f"   - ì´ ì¸í”Œë£¨ì–¸ì„œ: {raw_data['metadata']['total_count']}ëª…")
    print(f"   - ìƒíƒœ: {raw_data['metadata']['status']}")

    # 2. Processed ë°ì´í„° ìƒì„± (ë¶„ë¥˜/ë¶„ì„ ì™„ë£Œ í˜•ì‹)
    print("\n" + "=" * 60)
    print("2. Processed ë°ì´í„° ìƒì„± (ë¶„ë¥˜/ë¶„ì„ ì™„ë£Œ)")
    print("=" * 60)

    processed_data = generate_processed_data(num_experts=NUM_EXPERTS, num_trendsetters=NUM_TRENDSETTERS)
    processed_path = data_dir / "influencers_data.json"

    with open(processed_path, 'w', encoding='utf-8') as f:
        json.dump(processed_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… Processed ë°ì´í„° ìƒì„± ì™„ë£Œ: {processed_path}")
    print(f"   - ì´ ì¸í”Œë£¨ì–¸ì„œ: {processed_data['metadata']['total_count']}ëª…")
    print(f"   - Expert: {processed_data['metadata']['expert_count']}ëª…")
    print(f"   - Trendsetter: {processed_data['metadata']['trendsetter_count']}ëª…")
    print(f"   - ìŠ¤í‚¤ë§ˆ ë²„ì „: {processed_data['metadata']['schema_version']}")

    # í†µê³„ ì¶œë ¥
    stats = processed_data['metadata'].get('statistics', {})
    print("\nğŸ“Š FIS ì ìˆ˜ ë¶„í¬:")
    print(f"   - ì‹ ë¢° ê°€ëŠ¥ (80-98): {stats.get('fis_high', 0)}ëª…")
    print(f"   - ì£¼ì˜ í•„ìš” (60-79): {stats.get('fis_medium', 0)}ëª…")
    print(f"   - ìœ„í—˜ (40-59): {stats.get('fis_low', 0)}ëª…")

    print("\nğŸ‘¥ íƒ€ê²Ÿ ì¸êµ¬í†µê³„ ë¶„í¬:")
    print(f"   - 20ëŒ€ ì—¬ì„±: {stats.get('female_20', 0)}ëª…")
    print(f"   - 30ëŒ€ ì—¬ì„±: {stats.get('female_30', 0)}ëª…")
    print(f"   - 40ëŒ€ ì—¬ì„±: {stats.get('female_40', 0)}ëª…")
    print(f"   - 20ëŒ€ ë‚¨ì„±: {stats.get('male_20', 0)}ëª…")
    print(f"   - 30ëŒ€ ë‚¨ì„±: {stats.get('male_30', 0)}ëª…")
    print(f"   - ìœ ë‹ˆì„¹ìŠ¤: {stats.get('unisex', 0)}ëª…")

    # Expert ìƒ˜í”Œ ì¶œë ¥
    print("\nğŸ“Œ Expert ìƒ˜í”Œ:")
    for i in [0, 20, 40]:
        if i < len(processed_data["influencers"]):
            expert = processed_data["influencers"][i]
            if expert['influencer_type'] == 'expert':
                img = expert['image_analysis']
                print(f"   @{expert['username']} | {img.get('target_gender', 'N/A')} {img.get('target_age', 'N/A')} | FIS: {expert['fis']['score']} ({expert['fis']['verdict']})")

    # Trendsetter ìƒ˜í”Œ ì¶œë ¥
    print("\nğŸ“Œ Trendsetter ìƒ˜í”Œ:")
    for i in range(NUM_EXPERTS, min(NUM_EXPERTS + 10, len(processed_data["influencers"]))):
        trendsetter = processed_data["influencers"][i]
        if trendsetter['influencer_type'] == 'trendsetter':
            img = trendsetter['image_analysis']
            print(f"   @{trendsetter['username']} | {img.get('target_gender', 'N/A')} {img.get('target_age', 'N/A')} | FIS: {trendsetter['fis']['score']} ({trendsetter['fis']['verdict']})")


if __name__ == "__main__":
    main()
